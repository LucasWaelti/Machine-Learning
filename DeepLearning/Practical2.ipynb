{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Practical 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import dlc_practical_prologue as prologue\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset (reduced set)\n",
    "train_input, train_target, test_input, test_target = prologue.load_data(\n",
    "    cifar = None, one_hot_labels = False, normalize = False, flatten = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input size:  torch.Size([1000, 784])\n",
      "train_target size:  torch.Size([1000])\n",
      "test_input size:  torch.Size([1000, 784])\n",
      "test_target size:  torch.Size([1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lucas waelti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "c:\\users\\lucas waelti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\lucas waelti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "c:\\users\\lucas waelti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Convert arrays to tensor and check their dimensions\n",
    "train_input = torch.tensor(train_input)\n",
    "print('train_input size: ',train_input.size())\n",
    "\n",
    "train_target = torch.tensor(train_target)\n",
    "print('train_target size: ',train_target.size())\n",
    "\n",
    "test_input = torch.tensor(test_input)\n",
    "print('test_input size: ',test_input.size())\n",
    "\n",
    "test_target = torch.tensor(test_target)\n",
    "print('test_target size: ',test_target.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label:  tensor(6)\n",
      "True label:  tensor(6)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Exo 1) Nearest neighbours (k = 1)\n",
    "    Compute the label of a datapoint x, based on its nearest neighbour\n",
    "    train_input (n x d)\n",
    "    train_target (n)\n",
    "    x (1 X d) -> predict its label!\n",
    "'''\n",
    "def nearest_classification(train_input, train_target, x):\n",
    "    diff = train_input - x\n",
    "    diff2 = torch.pow(diff,2)\n",
    "    _sum = torch.sum(diff2,1)\n",
    "    \n",
    "    \n",
    "    # torch.sort(input, dim=None, descending=False, out=None) -> (sorted, indices)\n",
    "    _,indices = torch.sort(_sum, dim=0)\n",
    "    \n",
    "    return train_target[indices[0]]\n",
    "\n",
    "# Test the function with a chosen test sample\n",
    "id = 100\n",
    "print(\"Predicted label: \",nearest_classification(train_input,train_target,test_input[id,:]))\n",
    "print(\"True label: \",test_target[id])\n",
    "#plt.imshow(test_input[id,:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of prediction errors:  172\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Exo 2) Error estimation\n",
    "    Compute the predition for each datapoint of test_input. Count the number\n",
    "    of missclassified points and return it. \n",
    "    Demean both train_input and train_target. Apply the transformation\n",
    "    provided in proj (if not None). \n",
    "'''\n",
    "def compute_nb_errors(train_input, train_target, test_input, test_target,\n",
    "                        mean = None, proj = None):\n",
    "    if(mean is not None):\n",
    "        # Remove the provided mean \n",
    "        train_input = train_input - mean\n",
    "        test_input = test_input - mean\n",
    "        \n",
    "    if(proj is not None):\n",
    "        # Implement the provided projection\n",
    "        train_input = proj.mm(train_input.t()).t()\n",
    "        test_input = proj.mm(test_input.t()).t()\n",
    "        \n",
    "    # Classify the train and test inputs\n",
    "    nb_errors = 0\n",
    "    for x in range(0,test_input.size()[0]):\n",
    "        prediction = nearest_classification(train_input,train_target,test_input[x,:])\n",
    "        if(prediction.item() is not test_target[x].item()):\n",
    "            nb_errors = nb_errors + 1\n",
    "    \n",
    "    return nb_errors\n",
    "\n",
    "# Test the function \n",
    "print('Number of prediction errors: ',\n",
    "      compute_nb_errors(train_input.clone(), train_target.clone(), \n",
    "                        test_input.clone(), test_target.clone()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and A sizes:  torch.Size([784]) torch.Size([784, 784])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Exo 3) PCA\n",
    "    Compute the PCA of the dataset X (n x d). return the mean (1 x d) and the basis of the PCA\n",
    "'''\n",
    "def PCA(X):\n",
    "    # Demean the dataset\n",
    "    mean = torch.mean(X, dim=0)\n",
    "    X = X - mean\n",
    "    # Compute the covariance matrix C = 1/M*X'*X\n",
    "    M = X.size()[0]\n",
    "    C = (X.t()).mm(X)/(M - torch.tensor(1))\n",
    "                       \n",
    "    e,v = torch.eig(C, eigenvectors=True) # v has column vectors\n",
    "    e = e[:,0] # retrieve only the real parts\n",
    "    \n",
    "    # or use symeig instead since the matrix is symmetrical\n",
    "    #e,v = torch.symeig(C, eigenvectors=True)\n",
    "    #print(e,e.size())\n",
    "    \n",
    "    sorted, indices = torch.sort(e, dim=0, descending=True)\n",
    "    v = v[:,indices].t()\n",
    "    \n",
    "    return mean,v\n",
    "    \n",
    "# Build the mean and A matrix of the dataset\n",
    "mean,A = PCA(train_input.clone())\n",
    "print('Mean and A sizes: ',mean.size(), A.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors with Arand:  585\n",
      "Errors with A3:  597\n",
      "Errors with A10:  214\n",
      "Errors with A100:  164\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Exo 4) Apply PCA to the data set and evaluate the k-NN nearest neighbour (for k = 1)\n",
    "    Choose either 100 random eigenvectors or the first 3, 10, 50, 100 best eigenvectors.\n",
    "'''\n",
    "# Pick 100 random eigenvectors\n",
    "r = torch.randint(0, train_input.size()[1], (100,))\n",
    "Arand = A[r,:]\n",
    "\n",
    "# Pick the first n eigenvectors\n",
    "A3 = A[0:3,:]\n",
    "A10 = A[0:10,:]\n",
    "A50 = A[0:50,:]\n",
    "A100 = A[0:100,:]\n",
    "\n",
    "nb_errors_rand = compute_nb_errors(train_input.clone(), train_target.clone(), \n",
    "                        test_input.clone(), test_target.clone(),\n",
    "                        mean = mean, proj = Arand)\n",
    "print('Errors with Arand: ',nb_errors_rand)\n",
    "\n",
    "nb_errors_rand = compute_nb_errors(train_input.clone(), train_target.clone(), \n",
    "                        test_input.clone(), test_target.clone(),\n",
    "                        mean = mean, proj = A3)\n",
    "print('Errors with A3: ',nb_errors_rand)\n",
    "\n",
    "nb_errors_rand = compute_nb_errors(train_input.clone(), train_target.clone(), \n",
    "                        test_input.clone(), test_target.clone(),\n",
    "                        mean = mean, proj = A10)\n",
    "print('Errors with A10: ',nb_errors_rand)\n",
    "\n",
    "nb_errors_rand = compute_nb_errors(train_input.clone(), train_target.clone(), \n",
    "                        test_input.clone(), test_target.clone(),\n",
    "                        mean = mean, proj = A100)\n",
    "print('Errors with A100: ',nb_errors_rand)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
